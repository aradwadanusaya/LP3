{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******** ASSIGNMENT 3 *********\n",
    "# Dataset : Churn_Modelling.csv\n",
    "# Given a bank customer, build a neural networkbased classifier that can \n",
    "# determine whether they will leave or not in the next 6 months.\n",
    "\n",
    "# IMPORTING PYTHON MODULES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# LOADING THE DATASET : First we load the dataset and find out the number of columns, rows, NULL values etc.\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# CLEANING\n",
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)\n",
    "df.isna().sum()\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# SEPERATING THE FEATURES & LABELS\n",
    "X=df.iloc[:, :df.shape[1]-1].values #Independent Variables\n",
    "y=df.iloc[:, -1].values #Dependent Variable\n",
    "X.shape, y.shape\n",
    "\n",
    "# ENCODING CATEGORICAL (STRING BASED) DATA\n",
    "print(X[:8,1], '... will now become: ')\n",
    "label_X_country_encoder = LabelEncoder()\n",
    "X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n",
    "print(X[:8,1])\n",
    "\n",
    "print(X[:6,2], '... will now become: ')\n",
    "label_X_gender_encoder = LabelEncoder()\n",
    "X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n",
    "print(X[:6,2])\n",
    "\n",
    "# SPLIT THE COUNTRIES INTO RESPECTIVE DIMENSIONS. CONVERTING THE STRING FEATURES INTO THEIR OWN DIMENSIONS.\n",
    "transform = ColumnTransformer([(\"countries\", OneHotEncoder(), [1])], remainder=\"passthrough\") #\n",
    "X = transform.fit_transform(X)\n",
    "X\n",
    "\n",
    "# DIMENSIONALITY REDUCTION : A 0 ON TWO COUNTRIES MEANS THAT THE COUNTRY HAS TO BE ONE VARIABLE WHICH WASNT INCLUDED\n",
    "X = X[:,1:]\n",
    "X.shape\n",
    "\n",
    "# SPLITTING THE DATASET : Training & Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# NORMALISE THE TRAIN AND TEST DATA \n",
    "# ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "sc=StandardScaler()\n",
    "X_train[:,np.array([2,4,5,6,7,10])] = sc.fit_transform(X_train[:,np.array([2,4,5,6,7,10])])\n",
    "X_test[:,np.array([2,4,5,6,7,10])] = sc.transform(X_test[:,np.array([2,4,5,6,7,10])])\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train\n",
    "\n",
    "# INITIALISE AND BUILD THE MODEL\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Initializing the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Create a Sequential model\n",
    "classifier = Sequential()\n",
    "# Add a Dense layer to the model\n",
    "classifier.add(Dense(units=256, activation='relu', input_dim=11, kernel_initializer='uniform'))\n",
    "\n",
    "# Adding the hidden layer\n",
    "classifier.add(Dense(activation = 'relu', units=512, kernel_initializer='uniform'))\n",
    "classifier.add(Dense(activation = 'relu', units=256, kernel_initializer='uniform'))\n",
    "classifier.add(Dense(activation = 'relu', units=128, kernel_initializer='uniform'))\n",
    "\n",
    "# Adding the output layer\n",
    "# Notice that we do not need to specify input dim.\n",
    "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the\n",
    "# We use the sigmoid because we want probability outcomes\n",
    "classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform'))\n",
    "\n",
    "# Create optimizer with default learning rate\n",
    "# sgd_optimizer = tf.keras.optimizers.SGD()\n",
    "# Compile the model\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.fit(\n",
    " X_train, y_train,\n",
    " validation_data=(X_test,y_test),\n",
    " epochs=20,\n",
    " batch_size=32\n",
    ")\n",
    "\n",
    "# PREDICT THE RESULTS USING 0.5 AS A THRESHOLD\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "\n",
    "# To use the confusion Matrix, we need to convert the probabilities that a customer will leave t\n",
    "# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred\n",
    "\n",
    "\n",
    "# PRINT THE ACCURACY SCORE AND CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "cm1\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy_model1 = ((cm1[0][0]+cm1[1][1])*100)/(cm1[0][0]+cm1[1][1]+cm1[0][1]+cm1[1][0])\n",
    "print (accuracy_model1, '% of testing data was classified correctly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
